{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sourav.modi\\Documents\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from urllib.request import urlopen\n",
    "import optuna \n",
    "import functools\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "def opt(X_train, y_train, X_test, y_test, trial): \n",
    "    #param_list\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 400)\n",
    "#     tree_method = trial.suggest_categorical('tree_method', ['exact','approx','hist'])\n",
    "    objective = trial.suggest_categorical('objective', ['reg:linear'])\n",
    "    eval_metric = trial.suggest_categorical('eval_metric', ['rmse'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n",
    "    learning_rate = trial.suggest_discrete_uniform('learning_rate', 0.1, 0.11, 0.01)\n",
    "    subsample = trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)\n",
    "    colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1)\n",
    "    xgboost_tuna = xgb.XGBRegressor(\n",
    "        random_state=0, \n",
    "        n_estimators = n_estimators,\n",
    "#         tree_method = tree_method,\n",
    "        objective = objective,\n",
    "        eval_metric =eval_metric,\n",
    "        max_depth = max_depth,\n",
    "        min_child_weight = min_child_weight,\n",
    "        learning_rate = learning_rate,\n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "    )\n",
    "    xgboost_tuna.fit(X_train, y_train)\n",
    "    tuna_pred_test = xgboost_tuna.predict(X_test)\n",
    "#     return (median_absolute_error(y_test, tuna_pred_test))\n",
    "    return (np.sqrt(MSE(y_test, tuna_pred_test)))\n",
    "\n",
    "\n",
    "def weekendflag(df,weekdays):\n",
    "    df9=df.copy()\n",
    "    df9['ml']=df9['date'].apply(lambda x: x.weekday())\n",
    "    df9['weekend']=df9['ml'].apply(lambda x: 1 if(x in weekdays) else 0)\n",
    "    df9.drop(['ml'], axis=1,inplace=True)\n",
    "    return df9\n",
    "\n",
    "\n",
    "def XGBForecaster(df,frequency = 'hourly'):\n",
    "    if frequency == 'hourly':\n",
    "        df['date'] = pd.to_datetime(df['date'],format='%d-%m-%Y %H:%M')\n",
    "        df5 = df.copy()\n",
    "#         df5=zscore(df5)\n",
    "        df5 = create_features_hourly(df)\n",
    "        df5=weekendflag(df5,[5,6])\n",
    "        df5.sort_values('date',inplace=True)\n",
    "#         print(df5.info())\n",
    "#         print(df5)\n",
    "        df5[\"value\"] = df5[\"value\"].fillna(value=df5[\"value\"].mean())\n",
    "        df5 = df.set_index('date')\n",
    "        #     print(df5.info())\n",
    "        #     print(df5.head())\n",
    "\n",
    "        X = df5.loc[:,['temperature','var1','pressure','windspeed','var2','hour','dayofweek','quarter','month','year','dayofyear','dayofmonth','weekofyear','weekend']]\n",
    "        y=df5.loc[:,'value']\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=123)\n",
    "        print(y)\n",
    "        study = optuna.create_study()\n",
    "        study.optimize(functools.partial(opt, X_train, y_train, X_test, y_test), n_trials=100)\n",
    "        xg_reg5 = xgb.XGBRegressor(**study.best_params)\n",
    "        m5 =xg_reg5.fit(X,y)\n",
    "        \n",
    "        data_pred = pd.read_csv(r'test_pavJagI.csv')\n",
    "        data_pred5 =data_pred.copy()\n",
    "        data_pred5 =data_pred5.iloc[:,1:]\n",
    "        data_pred5['var2'] = data_pred5['var2'].map({'A': 0, 'B': 1,'C': 2})\n",
    "        data_pred5.rename(columns = {'datetime':'date'}, inplace = True)\n",
    "        data_pred5['date'] = pd.to_datetime(data_pred5['date'],format='%d-%m-%Y %H:%M')\n",
    "        data_pred5 = create_features_hourly1(data_pred5)\n",
    "        data_pred5=weekendflag(data_pred5,[5,6])\n",
    "        data = pd.DataFrame()\n",
    "        for year in data_pred5['date'].dt.year.unique():\n",
    "            data_pred6 = data_pred5[data_pred5['date'].dt.year == year]\n",
    "            data_pred6['date'] = pd.to_datetime(data_pred6['date'],format='%d-%m-%Y %H:%M')\n",
    "            for month in data_pred6['date'].dt.month.unique():\n",
    "                data_pred7 = data_pred6[data_pred6['date'].dt.month == month]\n",
    "                data_pred7['date'] = pd.to_datetime(data_pred7['date'],format='%d-%m-%Y %H:%M')\n",
    "                data_pred7.index=data_pred7['date']\n",
    "                data_pred7.drop('date',axis=1,inplace = True)\n",
    "                y_pred7 = pd.DataFrame(m5.predict(data_pred7),columns=['value']).values.flatten()\n",
    "    #     print(y_pred5)\n",
    "                data_pred7['value'] = y_pred7\n",
    "                data_pred7['date'] = data_pred7.index\n",
    "                outputDf=data_pred7[['date','value']]\n",
    "                print(outputDf.head(1))\n",
    "                data = data.append(outputDf)\n",
    "#                 print(data.head(2))\n",
    "#                 print(data.info())\n",
    "        data.to_csv('pred_all3.csv')   \n",
    "    return data\n",
    "  \n",
    "\n",
    "def create_features_hourly(df):\n",
    "    \"\"\"\n",
    "    Creates time series features from datetime index\n",
    "    \"\"\"\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.weekofyear\n",
    "\n",
    "    X = df[['temperature','var1','pressure','windspeed','var2',\n",
    "            'date',\n",
    "            'hour',\n",
    "            'dayofweek',\n",
    "            'quarter',\n",
    "            'month',\n",
    "            'year',\n",
    "            'dayofyear',\n",
    "            'dayofmonth',\n",
    "            'weekofyear','value']]\n",
    "    return X\n",
    "\n",
    "def create_features_hourly1(df):\n",
    "    \"\"\"\n",
    "    Creates time series features from datetime index\n",
    "    \"\"\"\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.weekofyear\n",
    "\n",
    "    X2 = df[['temperature','var1','pressure','windspeed','var2',\n",
    "             'date',\n",
    "             'hour',\n",
    "             'dayofweek',\n",
    "             'quarter',\n",
    "             'month',\n",
    "             'year',\n",
    "             'dayofyear',\n",
    "             'dayofmonth',\n",
    "             'weekofyear']]\n",
    "    return X2\n",
    "\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd,flush=True)\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(object):\n",
    "    def runMlAlgorithms(self,inputData2,upperLimit,lowerLimit,frequency='hourly'):\n",
    "        outputDf = XGBForecaster(inputData2,frequency = 'hourly')\n",
    "        outputDf['value'] = np.where(outputDf['value']<lowerLimit,lowerLimit,outputDf['value'])\n",
    "        outputDf['value'] = np.where(outputDf['value']>upperLimit,upperLimit,outputDf['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t = test()\n",
    "    inputData = pd.read_csv(r'train_6BJx641.csv')\n",
    "    inputData = inputData.iloc[:,1:]\n",
    "    inputData['var2'] = inputData['var2'].map({'A': 0, 'B': 1,'C': 2})\n",
    "#     print(inputData['var2'].dtypes)\n",
    "#     print(inputData['var2'].values)\n",
    "    inputData.rename(columns = {'datetime':'date', 'electricity_consumption':'value'}, inplace = True)\n",
    "    inputData['date'] = pd.to_datetime(inputData['date'],format='%Y-%m-%d %H:%M')\n",
    "    for year in inputData['date'].dt.year.unique():\n",
    "        inputData1 = inputData[inputData['date'].dt.year == year]\n",
    "        inputData1['date'] = pd.to_datetime(inputData1['date'],format='%Y-%m-%d %H:%M')\n",
    "        for month in inputData1['date'].dt.month.unique():\n",
    "            inputData2 = inputData1[inputData1['date'].dt.month == month]\n",
    "            inputData2['date'] = pd.to_datetime(inputData2['date'],format='%Y-%m-%d %H:%M')\n",
    "            t.runMlAlgorithms(inputData2,10000000000000000,0,frequency='hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "        import pandas as pd\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        df5 = pd.read_csv(r'train_6BJx641.csv')\n",
    "        X = df5.loc[:,['temperature','var1','pressure','windspeed','var2','hour','dayofweek','quarter','month','year','dayofyear','dayofmonth','weekofyear','weekend']]\n",
    "        y=df5.loc[:,'electricity_consumption']\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
